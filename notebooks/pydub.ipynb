{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eddebee8-9fb6-4fe5-9130-ad7534f8d125",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jovyan/work/notebooks\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'np' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 26\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;66;03m#audio chunks are combined here\u001b[39;00m\n\u001b[1;32m     25\u001b[0m audio_processed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msum\u001b[39m(audio_chunks)\n\u001b[0;32m---> 26\u001b[0m audio_processed \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241m.\u001b[39marray(audio_processed\u001b[38;5;241m.\u001b[39mget_array_of_samples())\n\u001b[1;32m     27\u001b[0m \u001b[38;5;66;03m#Note the processed audio rate is not the same - it would be 1K\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'np' is not defined"
     ]
    }
   ],
   "source": [
    "# Import required libraries\n",
    "import os\n",
    "\n",
    "from pydub.silence import split_on_silence\n",
    "from pydub import AudioSegment, effects \n",
    "from scipy.io.wavfile import read, write\n",
    "\n",
    "# Pass audio path\n",
    "path ='../assets/audio01.wav'\n",
    "assert os.path.isfile(path)\n",
    "\n",
    "rate, audio = read(path)\n",
    "# make the audio in pydub audio segment format\n",
    "aud = AudioSegment(audio.tobytes(),frame_rate = rate,\n",
    "                     sample_width = audio.dtype.itemsize,channels = 1)\n",
    "# use split on sience method to split the audio based on the silence, \n",
    "# here we can pass the min_silence_len as silent length threshold in ms and intensity thershold\n",
    "audio_chunks = split_on_silence(\n",
    "    aud,\n",
    "    min_silence_len = 2000,\n",
    "    silence_thresh = -45,\n",
    "    keep_silence = 500,)\n",
    "#audio chunks are combined here\n",
    "audio_processed = sum(audio_chunks)\n",
    "audio_processed = np.array(audio_processed.get_array_of_samples())\n",
    "#Note the processed audio rate is not the same - it would be 1K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86d9e49b-9950-46c4-a086-3f3cbc57311e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "055eba57-902e-4f6a-8329-7eaa4efd8be7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
